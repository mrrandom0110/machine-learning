{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "hw04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g1gwJfBicdI"
      },
      "source": [
        "## Интеллектуальный анализ данных – весна 2021\n",
        "## Домашнее задание 4: kNN. Линейные модели. Работа с признаками"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwirt3TicdM"
      },
      "source": [
        "Правила:\n",
        "\n",
        "* Домашнее задание оценивается в 10 баллов.\n",
        "\n",
        "* Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
        "\n",
        "* Можно использовать любые свободные источники с *обязательным* указанием ссылки на них.\n",
        "\n",
        "* Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
        "\n",
        "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXa0P01yicdO"
      },
      "source": [
        "### Задание 1:  Визуализация решающих поверхностей в kNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32YPkKy3icdP"
      },
      "source": [
        "В этом задании мы изобразим решающую поверхность для классификатора kNN, чтобы наглядно увидеть, как классификатор принимает решения для новых объектов. Для простоты будем работать со встроенным в `sklearn` набором данных `wine`, содержащим информацию о характеристиках трёх видов вина. Описание набора можно найти [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) и [здесь](https://rdrr.io/cran/rattle.data/man/wine.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LufeGZlicdP"
      },
      "source": [
        "Загрузим набор данных и сохраним информацию о признаках в переменную `X`, а о зависимой переменной – в переменную `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4SfRqrricdQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlVPKeM6icdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "f5a34e10-fddb-4d50-a295-12d9fd8a939e"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "data = load_wine()\n",
        "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
        "y = data['target']\n",
        "X.head(8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14.20</td>\n",
              "      <td>1.76</td>\n",
              "      <td>2.45</td>\n",
              "      <td>15.2</td>\n",
              "      <td>112.0</td>\n",
              "      <td>3.27</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.97</td>\n",
              "      <td>6.75</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2.85</td>\n",
              "      <td>1450.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14.39</td>\n",
              "      <td>1.87</td>\n",
              "      <td>2.45</td>\n",
              "      <td>14.6</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.52</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.98</td>\n",
              "      <td>5.25</td>\n",
              "      <td>1.02</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1290.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14.06</td>\n",
              "      <td>2.15</td>\n",
              "      <td>2.61</td>\n",
              "      <td>17.6</td>\n",
              "      <td>121.0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.31</td>\n",
              "      <td>1.25</td>\n",
              "      <td>5.05</td>\n",
              "      <td>1.06</td>\n",
              "      <td>3.58</td>\n",
              "      <td>1295.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  ...   hue  od280/od315_of_diluted_wines  proline\n",
              "0    14.23        1.71  2.43  ...  1.04                          3.92   1065.0\n",
              "1    13.20        1.78  2.14  ...  1.05                          3.40   1050.0\n",
              "2    13.16        2.36  2.67  ...  1.03                          3.17   1185.0\n",
              "3    14.37        1.95  2.50  ...  0.86                          3.45   1480.0\n",
              "4    13.24        2.59  2.87  ...  1.04                          2.93    735.0\n",
              "5    14.20        1.76  2.45  ...  1.05                          2.85   1450.0\n",
              "6    14.39        1.87  2.45  ...  1.02                          3.58   1290.0\n",
              "7    14.06        2.15  2.61  ...  1.06                          3.58   1295.0\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGwmaGMTicdS"
      },
      "source": [
        "**Задача 1.1 (0.5 балла)** Есть ли в наборе данных пропущенные значения? Если да, то удалите их. Есть ли в наборе данных категориальные переменные? Если да, то закодируйте их при помощи OneHot-кодирования."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l9NM8oFicdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexzerRxicdT"
      },
      "source": [
        "**Задача 1.2 (0.5 балла)** Используя функцию `train_test_split()`, разделите выборку на тренировочную и тестовую, и долю тестовой выборки задайте равной 0.3. Так как разбиение осуществляется случайным образом, не забудьте зафиксировать `np.random.seed()` для воспроизводимости результатов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK1MR373icdU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOpp9X7IicdU"
      },
      "source": [
        "**Задача 1.3 (1 балл)** На тренировочной выборке обучите шесть классификаторов kNN, отличающихся только числом соседей. Для первого классификатора число соседей поставьте равным 1, для второго - 3, для третьего – 5, для четвертого – 10, для пятого – 15 и для шестого – 25 (обратите внимание на параметр `n_neighbours` класса `KNeighborsClassifier`). Для обучения используйте только два признака: `alcohol` и `magnesium` – и евклидово расстояние. Не забудьте масштабировать признаки, например, при помощи модуля `StandardScaler`.\n",
        "\n",
        "Выведите долю правильных ответов на тренировочной и тестовой выборках для каждого классификатора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ8JAQxiicdV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbznUcbxicdV"
      },
      "source": [
        "**Задача 1.4 (0 баллов)** Установите библиотеку `mlxtend` командой ниже. Библиотеку также можно установить из терминала при помощи `pip` или `conda`, как указано [здесь](http://rasbt.github.io/mlxtend/installation/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoho1CTcicdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115bfe5a-7a36-450f-9e72-ccbb83053ae8"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (56.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQqMLR6dicdW"
      },
      "source": [
        "Если всё прошло успешно, то в выводе команды выше вы увидите сообщение вроде \"successfully installed\", а следующая ячейка выполнится без ошибок."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOhdQ-HwicdX"
      },
      "source": [
        "import mlxtend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGIn9F9BicdX"
      },
      "source": [
        "**Задача 1.5 (1 балл)** Библиотека `mlxtend` позволяет достаточно просто визуализировать решающие поверхности обученных классификаторов. Изучите [документацию](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/) библиотеки и найдите, как можно построить несколько графиков решающих поверхностей на сетке (decision regions grid). Постройте такую сетку графиков для обученных выше классификаторов.\n",
        "\n",
        "**Подсказки:**\n",
        "1. Вы можете использовать готовый код, приведённый в документации, и адаптировать его для нашего случая.\n",
        "2. Вам могут понадобиться дополнительные библиотеки, которые используются в примере из документации.\n",
        "3. Обратите внимание на то, как нужно изменить параметры `gridspec.GridSpec()` и `itertools.product()` для нашего числа классификаторов. \n",
        "4. В функции `plot_decision_region()` используйте `y_train` и нужные столбцы из `X_train`. Возможно, их придётся перевести в формат массива `numpy`.\n",
        "5. Если в задаче 1.3 вы сохраните обученные классификаторы в список, то не будет необходимости обучать их заново. \n",
        "6. Построение графика может занять некоторое время – придётся немного подождать!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vk-rgCGicdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgg9kBKticdZ"
      },
      "source": [
        "**Задача 1.6 (0.5 балла)** Прокомментируйте результаты, полученные в задачах 1.3 и 1.5. Какое число соседей оптимально использовать для обучения классификатора? Поясните ваш выбор при помощи описания геометрии данных и получаемой решающей поверхности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-S5wKfwicdZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8e5DGmKicdZ"
      },
      "source": [
        "### Задание 2: Обученная машина."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kmkJf3icda"
      },
      "source": [
        "В этом задании мы рассмотрим упрощённую идею того, как метод ближайших соседей можно применить при моделировании движения робота. \n",
        "\n",
        "Рассмотрим робота на дискретной двумерной плоскости, который за каждый момент дискретного времени может передвинуться на одну позицию вправо, влево, вверх или вниз. На плоскости разбросаны метки одного из четырёх классов, анализируя которые робот может (но не обязан) корректировать своё перемещение. Пусть метки класса 0 соответствуют сигналу переместиться вправо, метки класса 1 – влево, класса 2 – вверх, класса 3 – вниз. \n",
        "\n",
        "Передвижение робота осуществляется по следующему правилу: с вероятностью 0.2 робот передвинется вправо, и с вероятностью 0.8 – оценит, метки какого класса преобладают среди `k` его ближайших соседей, и передвинется в направлении этого доминирующего класса. \n",
        "\n",
        "Для лучшего понимания происходящего изобразим возможное положение робота и меток:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR7tk191icda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "c5e92f17-742a-438b-f5ae-9d7fe3340346"
      },
      "source": [
        "np.random.seed(12345)\n",
        "x = np.arange(20)\n",
        "landmarks = x + np.round(np.random.normal(2, 8, 20)) # сгенерируем случайные метки\n",
        "random_classes = np.random.randint(0, 4, 20)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 7))\n",
        "scatter = ax.scatter(x, landmarks, c = random_classes)\n",
        "ax.scatter(4, 7, c = 'r', marker = 'o', label = 'robot position')\n",
        "legend1 = ax.legend(*scatter.legend_elements(),\n",
        "                    loc = \"lower left\", title = \"Classes\")\n",
        "ax.add_artist(legend1)\n",
        "\n",
        "plt.plot()\n",
        "_ = plt.legend()\n",
        "_ = plt.grid()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqgdKbLUicdb"
      },
      "source": [
        "На следующем шаге робот передвинется на 1 либо вправо, либо в направлении, которое указывают ближайшие соседи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u54pit08icdc"
      },
      "source": [
        "**Задача 2.1 (1.5 балла)** Реализуйте класс, который задаёт описанное поведение робота, используя шаблон ниже:\n",
        "1. Определите атрибуты `trajectory` (переменная для хранения истории перемещения робота в виде последовательности точек с двумя координатами) и `knn` (обученный kNN классификатор, который по позиции метки предсказывает её класс).\n",
        "2. Определите метод `move()`: рассчитайте новое положение робота по правилам выше и добавьте её в историю перемещений. Подсказка: исходы можно интерпретировать как результаты подбрасывания монетки с вероятностью орла, равной 0.2. Для моделирования такого подбрасывания можно использовать, например, `np.random.binomial()` с правильными параметрами. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drCn8fmoicdd"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytu9upQpicdi"
      },
      "source": [
        "**Задача 2.2 (0.5 балла)** Дополните функцию `conduct_experiment`: определите переменную `traj` так, чтобы она содержала историю перемещения робота в виде двумерного массива numpy, в котором столбцы соответствуют координатам x и y соответствующей позиции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijQnDzwmicdk"
      },
      "source": [
        "**Задача 2.3 (1 балл)** Как число соседей влияет на траекторию движения робота в нашем эксперименте? Постройте четыре графика с различным числом соседей на ваш выбор. А что было бы в случае, если классы назначаются меткам не случайно, а осмысленно? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDAT84bSicdk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B5zb0Q2icdk"
      },
      "source": [
        "### Задание 3: Линейная регрессия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmfbTxr4icdl"
      },
      "source": [
        "В этом задании мы рассмотрим различные аспекты построения линейной модели. Мы будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах. Описание можно посмотреть [здесь](https://www.kaggle.com/shivam2503/diamonds)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6655R-bi2q8"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuPzRvxpjChZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4eGMrLSLicdl",
        "outputId": "d17c345d-2763-4871-b48b-67dd78869c88"
      },
      "source": [
        "data = pd.read_csv('diamonds.csv')\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  carat      cut color clarity  ...  table  price     x     y     z\n",
              "0           1   0.23    Ideal     E     SI2  ...   55.0    326  3.95  3.98  2.43\n",
              "1           2   0.21  Premium     E     SI1  ...   61.0    326  3.89  3.84  2.31\n",
              "2           3   0.23     Good     E     VS1  ...   65.0    327  4.05  4.07  2.31\n",
              "3           4   0.29  Premium     I     VS2  ...   58.0    334  4.20  4.23  2.63\n",
              "4           5   0.31     Good     J     SI2  ...   58.0    335  4.34  4.35  2.75\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2uOBiHicdl"
      },
      "source": [
        "Мы будем решать задачу предсказания цены бриллианта `price` в зависимости от его характеристик."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT75v5YEicdm"
      },
      "source": [
        "**Задача 3.1 (0.1 балла)** Есть ли в наборе данных пропущенные значения? Если да, удалите их. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwQPpCb_icdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f232c32a-50c5-4e5b-db6f-bc96fba650b7"
      },
      "source": [
        "data.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri6epr_vicdm"
      },
      "source": [
        "**Задача 3.2 (0.1 балла)** Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)? Если да, то удалите их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLiQnGIPicdm"
      },
      "source": [
        "\n",
        "data.head()\n",
        "y = data['price']\n",
        "X = data.drop(labels = 'price',axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mShDa62Jlzx1"
      },
      "source": [
        "X = data\n",
        "X.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3-w1FK6CUrVl",
        "outputId": "fd36b460-8514-43ad-af47-e4bcf7c06c45"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53935</th>\n",
              "      <td>0.72</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>60.8</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5.75</td>\n",
              "      <td>5.76</td>\n",
              "      <td>3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53936</th>\n",
              "      <td>0.72</td>\n",
              "      <td>Good</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>63.1</td>\n",
              "      <td>55.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>5.75</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53937</th>\n",
              "      <td>0.70</td>\n",
              "      <td>Very Good</td>\n",
              "      <td>D</td>\n",
              "      <td>SI1</td>\n",
              "      <td>62.8</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.68</td>\n",
              "      <td>3.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53938</th>\n",
              "      <td>0.86</td>\n",
              "      <td>Premium</td>\n",
              "      <td>H</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>6.15</td>\n",
              "      <td>6.12</td>\n",
              "      <td>3.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53939</th>\n",
              "      <td>0.75</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>D</td>\n",
              "      <td>SI2</td>\n",
              "      <td>62.2</td>\n",
              "      <td>55.0</td>\n",
              "      <td>5.83</td>\n",
              "      <td>5.87</td>\n",
              "      <td>3.64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53940 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       carat        cut color clarity  depth  table     x     y     z\n",
              "0       0.23      Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
              "1       0.21    Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
              "2       0.23       Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
              "3       0.29    Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
              "4       0.31       Good     J     SI2   63.3   58.0  4.34  4.35  2.75\n",
              "...      ...        ...   ...     ...    ...    ...   ...   ...   ...\n",
              "53935   0.72      Ideal     D     SI1   60.8   57.0  5.75  5.76  3.50\n",
              "53936   0.72       Good     D     SI1   63.1   55.0  5.69  5.75  3.61\n",
              "53937   0.70  Very Good     D     SI1   62.8   60.0  5.66  5.68  3.56\n",
              "53938   0.86    Premium     H     SI2   61.0   58.0  6.15  6.12  3.74\n",
              "53939   0.75      Ideal     D     SI2   62.2   55.0  5.83  5.87  3.64\n",
              "\n",
              "[53940 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkV7iAZficdm"
      },
      "source": [
        "**Задача 3.3 (0.1 балла)** Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Для следующих пунктов нам также потребуются выборочные корреляции между признаками. Выведите матрицу выборочных корреляций между всеми вещественными признаками и целевой переменной (то есть в этой матрице будет $k+1$ строка, где $k$ – количество вещественных признаков).\n",
        "\n",
        "Какие вещественные признаки коррелируют с целевой переменной больше всего?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVu2Yyjaicdn",
        "outputId": "3ca912d7-4e22-4c31-e907-9d0e1c1deda9"
      },
      "source": [
        "X.corrwith(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0   -0.306873\n",
              "carat         0.921591\n",
              "depth        -0.010647\n",
              "table         0.127134\n",
              "x             0.884435\n",
              "y             0.865421\n",
              "z             0.861249\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSOJwITGicdn"
      },
      "source": [
        "**Задача 3.4 (0.1 балла)** Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "RQv2V9h7icdn",
        "outputId": "b6cb4ba2-99bd-4afd-b0aa-8bb83b9a1dc9"
      },
      "source": [
        "X.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  carat      cut color clarity  depth  table     x     y     z\n",
              "0           1   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
              "1           2   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
              "2           3   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
              "3           4   0.29  Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
              "4           5   0.31     Good     J     SI2   63.3   58.0  4.34  4.35  2.75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u20cAcFmnjeX"
      },
      "source": [
        "cat_features_mask = (X.dtypes == \"object\").values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJyLJMe7n9Xj",
        "outputId": "bb2f18a2-7e35-4eff-beaf-cda95a1b7f32"
      },
      "source": [
        "cat_features_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True,  True, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5pYeprOicdn"
      },
      "source": [
        "**Задача 3.5 (0.2 балла)** Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной 0.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "t2FCc_wQicdn",
        "outputId": "0bedb86c-635d-4726-e60d-9a35628a1e07"
      },
      "source": [
        "X_real = X[X.columns[~cat_features_mask]]\n",
        "X_object = X[X.columns[cat_features_mask]]\n",
        "new_data = pd.get_dummies(X_object,drop_first=True)\n",
        "X = pd.concat([X_real,new_data],axis=1)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut_Good</th>\n",
              "      <th>cut_Ideal</th>\n",
              "      <th>cut_Premium</th>\n",
              "      <th>cut_Very Good</th>\n",
              "      <th>color_E</th>\n",
              "      <th>color_F</th>\n",
              "      <th>color_G</th>\n",
              "      <th>color_H</th>\n",
              "      <th>color_I</th>\n",
              "      <th>color_J</th>\n",
              "      <th>clarity_IF</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53935</th>\n",
              "      <td>0.72</td>\n",
              "      <td>60.8</td>\n",
              "      <td>57.0</td>\n",
              "      <td>5.75</td>\n",
              "      <td>5.76</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53936</th>\n",
              "      <td>0.72</td>\n",
              "      <td>63.1</td>\n",
              "      <td>55.0</td>\n",
              "      <td>5.69</td>\n",
              "      <td>5.75</td>\n",
              "      <td>3.61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53937</th>\n",
              "      <td>0.70</td>\n",
              "      <td>62.8</td>\n",
              "      <td>60.0</td>\n",
              "      <td>5.66</td>\n",
              "      <td>5.68</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53938</th>\n",
              "      <td>0.86</td>\n",
              "      <td>61.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>6.15</td>\n",
              "      <td>6.12</td>\n",
              "      <td>3.74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53939</th>\n",
              "      <td>0.75</td>\n",
              "      <td>62.2</td>\n",
              "      <td>55.0</td>\n",
              "      <td>5.83</td>\n",
              "      <td>5.87</td>\n",
              "      <td>3.64</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53940 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       carat  depth  table  ...  clarity_VS2  clarity_VVS1  clarity_VVS2\n",
              "0       0.23   61.5   55.0  ...            0             0             0\n",
              "1       0.21   59.8   61.0  ...            0             0             0\n",
              "2       0.23   56.9   65.0  ...            0             0             0\n",
              "3       0.29   62.4   58.0  ...            1             0             0\n",
              "4       0.31   63.3   58.0  ...            0             0             0\n",
              "...      ...    ...    ...  ...          ...           ...           ...\n",
              "53935   0.72   60.8   57.0  ...            0             0             0\n",
              "53936   0.72   63.1   55.0  ...            0             0             0\n",
              "53937   0.70   62.8   60.0  ...            0             0             0\n",
              "53938   0.86   61.0   58.0  ...            0             0             0\n",
              "53939   0.75   62.2   55.0  ...            0             0             0\n",
              "\n",
              "[53940 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG7d1l1Iicdo"
      },
      "source": [
        "**Задача 3.6 (0.3 балла)** Зачастую при использовании линейных моделей вещественные признаки масштабируются. При этом оценки коэффициентов теряют прямую статистическую интерпретацию (\"при увеличении $X_1$ на 1, $y$ увеличивается на $w_1$\"), но приобретают свойства, полезные в задачах машинного обучения. В этой задаче масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля `StandardScaler`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "s6SzfeU7icdo",
        "outputId": "237c34a8-d4ee-4a73-da29-0714f1d2912d"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "new_data2 = pd.DataFrame(data = scaler.fit_transform(X_real),columns = X_real.columns)\n",
        "x = pd.concat([new_data2,new_data],axis = 1)\n",
        "x.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut_Good</th>\n",
              "      <th>cut_Ideal</th>\n",
              "      <th>cut_Premium</th>\n",
              "      <th>cut_Very Good</th>\n",
              "      <th>color_E</th>\n",
              "      <th>color_F</th>\n",
              "      <th>color_G</th>\n",
              "      <th>color_H</th>\n",
              "      <th>color_I</th>\n",
              "      <th>color_J</th>\n",
              "      <th>clarity_IF</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.198168</td>\n",
              "      <td>-0.174092</td>\n",
              "      <td>-1.099672</td>\n",
              "      <td>-1.587837</td>\n",
              "      <td>-1.536196</td>\n",
              "      <td>-1.571129</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.240361</td>\n",
              "      <td>-1.360738</td>\n",
              "      <td>1.585529</td>\n",
              "      <td>-1.641325</td>\n",
              "      <td>-1.658774</td>\n",
              "      <td>-1.741175</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.198168</td>\n",
              "      <td>-3.385019</td>\n",
              "      <td>3.375663</td>\n",
              "      <td>-1.498691</td>\n",
              "      <td>-1.457395</td>\n",
              "      <td>-1.741175</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.071587</td>\n",
              "      <td>0.454133</td>\n",
              "      <td>0.242928</td>\n",
              "      <td>-1.364971</td>\n",
              "      <td>-1.317305</td>\n",
              "      <td>-1.287720</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.029394</td>\n",
              "      <td>1.082358</td>\n",
              "      <td>0.242928</td>\n",
              "      <td>-1.240167</td>\n",
              "      <td>-1.212238</td>\n",
              "      <td>-1.117674</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      carat     depth     table  ...  clarity_VS2  clarity_VVS1  clarity_VVS2\n",
              "0 -1.198168 -0.174092 -1.099672  ...            0             0             0\n",
              "1 -1.240361 -1.360738  1.585529  ...            0             0             0\n",
              "2 -1.198168 -3.385019  3.375663  ...            0             0             0\n",
              "3 -1.071587  0.454133  0.242928  ...            1             0             0\n",
              "4 -1.029394  1.082358  0.242928  ...            0             0             0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrfgcuBMicdo"
      },
      "source": [
        "**Задача 3.7 (0.2 балла)** Оцените линейную регрессию на тренировочной выборке. Выведите среднеквадратичную ошибку на тренировочной и тестовой выборках."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKywkBT4icdo",
        "outputId": "a579a461-51f3-434e-d34e-95b239464dec"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(5)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 41, shuffle = True)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "clf = LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred_train = clf.predict(x_train)\n",
        "y_pred_test = clf.predict(x_test)\n",
        "MSE_train = mean_squared_error(y_train,y_pred_train)\n",
        "MSE_test = mean_squared_error(y_test,y_pred_test)\n",
        "print(\"MSE_train {}\".format(MSE_train))\n",
        "print(\"MSE_test {}\".format(MSE_test))\n",
        "clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE_train 1234877.5261131392\n",
            "MSE_test 1378046.960236092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-89.16590583091056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51SvOKRFicdp"
      },
      "source": [
        "**Задача 3.8 (0.2 балла)** Изучите документацию модуля `LinearRegression` и выведите полученные оценки коэффициентов. Назовите вещественные переменные, оценки коэффициентов которых по модулю на порядок превышают оценки прочих вещественных переменных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J944i1nNicdp",
        "outputId": "8b94eb59-5468-4771-e452-6aad339d66f6"
      },
      "source": [
        "clf.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.64709922e+01,  5.43504561e+03, -8.84805347e+01, -6.15184545e+01,\n",
              "       -1.16655811e+03, -3.49912939e+00, -5.32519355e+01,  6.33041421e+02,\n",
              "        8.73137582e+02,  8.07731586e+02,  7.80758716e+02, -2.11987963e+02,\n",
              "       -2.74016553e+02, -4.86549377e+02, -9.65799888e+02, -1.46974627e+03,\n",
              "       -2.37261116e+03,  5.19671076e+03,  3.53519009e+03,  2.56630021e+03,\n",
              "        4.43241680e+03,  4.13319046e+03,  4.85418633e+03,  4.80642443e+03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "2HvWyTiZuRbL",
        "outputId": "321b3d66-221d-4918-bf28-1ffe56f78302"
      },
      "source": [
        "X_real.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.377983</td>\n",
              "      <td>-0.034800</td>\n",
              "      <td>-0.100830</td>\n",
              "      <td>-0.405440</td>\n",
              "      <td>-0.395843</td>\n",
              "      <td>-0.399208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carat</th>\n",
              "      <td>-0.377983</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028224</td>\n",
              "      <td>0.181618</td>\n",
              "      <td>0.975094</td>\n",
              "      <td>0.951722</td>\n",
              "      <td>0.953387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depth</th>\n",
              "      <td>-0.034800</td>\n",
              "      <td>0.028224</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.295779</td>\n",
              "      <td>-0.025289</td>\n",
              "      <td>-0.029341</td>\n",
              "      <td>0.094924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>table</th>\n",
              "      <td>-0.100830</td>\n",
              "      <td>0.181618</td>\n",
              "      <td>-0.295779</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>0.183760</td>\n",
              "      <td>0.150929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <td>-0.405440</td>\n",
              "      <td>0.975094</td>\n",
              "      <td>-0.025289</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.974701</td>\n",
              "      <td>0.970772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>-0.395843</td>\n",
              "      <td>0.951722</td>\n",
              "      <td>-0.029341</td>\n",
              "      <td>0.183760</td>\n",
              "      <td>0.974701</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.952006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>-0.399208</td>\n",
              "      <td>0.953387</td>\n",
              "      <td>0.094924</td>\n",
              "      <td>0.150929</td>\n",
              "      <td>0.970772</td>\n",
              "      <td>0.952006</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Unnamed: 0     carat     depth  ...         x         y         z\n",
              "Unnamed: 0    1.000000 -0.377983 -0.034800  ... -0.405440 -0.395843 -0.399208\n",
              "carat        -0.377983  1.000000  0.028224  ...  0.975094  0.951722  0.953387\n",
              "depth        -0.034800  0.028224  1.000000  ... -0.025289 -0.029341  0.094924\n",
              "table        -0.100830  0.181618 -0.295779  ...  0.195344  0.183760  0.150929\n",
              "x            -0.405440  0.975094 -0.025289  ...  1.000000  0.974701  0.970772\n",
              "y            -0.395843  0.951722 -0.029341  ...  0.974701  1.000000  0.952006\n",
              "z            -0.399208  0.953387  0.094924  ...  0.970772  0.952006  1.000000\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rue2Srhhicdp"
      },
      "source": [
        "**Задача 3.9 (0.4 балла)** Как можно заметить из анализа корреляционной матрицы в задаче 3.3, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы *мультиколлинеарности*. Различия в порядке коэффициентов, выявленные в предыдущей задаче также намекают на её присутствие. Как известно, для решения этой проблемы можно либо исключить некоторые признаки из модели, либо использовать регуляризацию. Мы воспользуемся вторым вариантом. \n",
        "\n",
        "Вспомним, что смысл регуляризации заключается в том, чтобы изменить функцию потерь так, чтобы устранить проблемы, появляющиеся из-за мультиколлинеарности. При L1-регуляризации предлагается минимизировать следующую функцию потерь:\n",
        "\n",
        "$$\n",
        "\\|y - X\\hat{w}\\|^2 + \\alpha\\sum_{i=1}^k|w_i|\n",
        "$$\n",
        "\n",
        "Такая модель называется Lasso-регрессией.\n",
        "\n",
        "При L2-регуляризации предлагается минимизировать следующую функцию потерь:\n",
        "\n",
        "$$\n",
        "\\|y - X\\hat{w}\\|^2 + \\frac{1}{2}\\alpha\\|w\\|^2\n",
        "$$\n",
        "\n",
        "Такая модель называется Ridge-регрессией. \n",
        "\n",
        "Обучите Lasso-регрессию и Ridge-регрессию, уставновив гиперпараметр регуляризации равным 10. Для этого используйте модули `Lasso` и `Ridge` из `sklearn`. Сильно ли уменьшились веса? Сделайте вывод о том, насколько сильно проблема мультиколлинеарности проявлялась в изначальной регрессии."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5BSFc8Yicdp",
        "outputId": "398310a2-9e10-4316-8b1b-2bf06d3965eb"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "clf = Lasso(alpha = 10)\n",
        "clf.fit(x_train,y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "clf.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   76.22290056,  4880.0693257 ,  -153.26233923,  -111.06198391,\n",
              "        -764.70078448,    -0.        ,   -26.84635597,    -0.        ,\n",
              "         154.82526941,    71.20401101,    89.25877381,     0.        ,\n",
              "          -0.        ,  -122.18618515,  -594.25424734,  -993.03353413,\n",
              "       -1783.43526326,  1287.45071915,     0.        ,  -821.17551664,\n",
              "         799.594035  ,   571.71293572,  1125.56554288,  1146.57390146])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoRE0U8hw6Pk",
        "outputId": "a5a780f9-8566-404c-f0b7-ffc1bb250650"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "clf = Ridge(alpha = 10)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.coef_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.68211045e+01,  5.38507137e+03, -8.99241817e+01, -6.43906805e+01,\n",
              "       -1.11643897e+03, -1.58194611e+00, -6.73557823e+01,  6.54320677e+02,\n",
              "        8.98546163e+02,  8.29767158e+02,  8.08137885e+02, -2.00142626e+02,\n",
              "       -2.61019269e+02, -4.69271296e+02, -9.49205299e+02, -1.44403974e+03,\n",
              "       -2.33666271e+03,  4.62714283e+03,  3.00895753e+03,  2.04735580e+03,\n",
              "        3.89710359e+03,  3.60363783e+03,  4.30573393e+03,  4.26513230e+03])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l3wKG01icdp"
      },
      "source": [
        "**Задача 3.10 (0.4 балла)** Как обсуждалось на семинарах, Lasso-регрессию можно использовать для отбора наиболее информативных признаков. Для следующих значений параметра регуляриазции $\\alpha$: 0.1, 1, 10, 100, 200 –  обучите Lasso- и Ridge-регрессии и постройте график измненения евклидовой нормы весов (`np.linalg.norm()` от вектора оценок коэффициентов) в зависимости от параметра $\\alpha$. Как известно, норма является численной характеристикой величины вектора, а потому по норме можно судить о том, насколько большие элементы содержит вектор оценок коэффициентов. \n",
        "\n",
        "Какой метод агрессивнее уменьшает веса? Поясните, почему Lasso-регрессию часто используют для отбора признаков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kNhqvqicdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e699a7ed-1b5d-4dd7-e284-a5a41a38f89e"
      },
      "source": [
        "alpha_grid = [0.1,1,10,100,200]\n",
        "classifier = []\n",
        "for a in alpha_grid:\n",
        "  clf = Lasso(alpha = a)\n",
        "  clf.fit(x_train,y_train)\n",
        "  classifier.append(clf)\n",
        "  y_predicted = clf.predict(x_train)\n",
        "  print(mean_squared_error(y_train,y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1230143.5531714146\n",
            "1234691.9280925211\n",
            "1454209.8657512632\n",
            "2183904.8164424384\n",
            "2396446.7783595924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGP4HYwzXRBm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "axis_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFLyboAvYmaX",
        "outputId": "94bb1457-a719-4240-ef37-c89e3dac7a34"
      },
      "source": [
        "for i in range(len(classifier)):\n",
        "  axis_x.append(np.linalg.norm(classifier[i].coef_))\n",
        "\n",
        "np.sort(axis_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3485.02028782,  3691.30819781,  5907.0826627 , 11851.07328228,\n",
              "       12983.95004831])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dtL0WaG0Z0Hc",
        "outputId": "d0fa07f5-2e3f-4f98-b720-682ba58a1f33"
      },
      "source": [
        "plt.plot(alpha_grid,axis_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f04d811d250>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt3W0676IRwa"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B00dFjv-JAzB"
      },
      "source": [
        "gs_cv = GridSearchCV(Lasso(), param_grid = {'alpha':alpha_grid}, verbose= 1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4ouQvKAJ0aC",
        "outputId": "5b0b3a98-659d-415a-afb1-46fd758c074c"
      },
      "source": [
        "gs_cv.fit(x_train,y_train)\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1036287087.6872597, tolerance: 48235041.79781578\n",
            "  positive)\n",
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    4.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fflwozPKKPrd",
        "outputId": "1c7311e0-75bd-4b2f-8e48-36f8011eac77"
      },
      "source": [
        "gs_cv.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kHEg53ELt0J",
        "outputId": "5d4611ed-4c0b-4da9-9120-fea5dc41e43f"
      },
      "source": [
        "mean_squared_error(y_train,gs_cv.predict(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1234691.9280925211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BfYn-7zicdq"
      },
      "source": [
        "**Задача 3.11 (0.5 балла)** \n",
        "В зависимости от значения параметра $\\alpha$ в Lasso-регрессии зануляются разные оценки коэффициентов. Оптимальное значение $\\alpha$ можно подобрать, например, при помощи кросс-валидации по тренировочной выборке. \n",
        "\n",
        "Для проведения кросс-валидации можно использовать модуль `LassoCV`. Этот модуль принимает список значений $\\alpha$ (параметр `alphas`) и при обучении проводит кросс-валидацию для каждого значения из этого списка, сохраняя MSE на каждом участке кросс-валидации (количество участков – параметр `cv`) в матрицу ошибок (то есть итоговая матрица будет иметь размер `len(alphas)` $\\times$ `cv`). После обучения модели матрицу ошибок можно получить, обратившись к атрибуту `.mse_path_`. \n",
        "\n",
        "Заметим, что модель может использовать $\\alpha$ не в том порядке, в котором вы подаёте их в функцию: для определения порядка используйте атрибут `.alphas_` Установите количество участков для кросс-валидации (параметр `cv`) равным 5.\n",
        "\n",
        "Усредните ошибки для каждого значения $\\alpha$ (то есть по строкам матрицы ошибок) и выберите то значение, которое даёт наибольшее качество. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjL4GXfSI_9L"
      },
      "source": [
        "from sklearn.linear_model import LassoCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aGIcaJHicdq"
      },
      "source": [
        "LCV = LassoCV(alphas = alpha_grid, cv = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdQkWkvhNgEO",
        "outputId": "5ef34f10-dd5d-4aba-b632-295503ed89cf"
      },
      "source": [
        "LCV.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1727926697.5259247, tolerance: 48235041.79781577\n",
            "  tol, rng, random, positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LassoCV(alphas=[0.1, 1, 10, 100, 200], copy_X=True, cv=5, eps=0.001,\n",
              "        fit_intercept=True, max_iter=1000, n_alphas=100, n_jobs=None,\n",
              "        normalize=False, positive=False, precompute='auto', random_state=None,\n",
              "        selection='cyclic', tol=0.0001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq1XLymbPiWa",
        "outputId": "1af4cae7-e74e-4482-ccc5-198b659a2d37"
      },
      "source": [
        "alpha_grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1, 1, 10, 100, 200]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvi1gVv9PPO3",
        "outputId": "e21bab93-cfdf-492b-fc54-8e2a676b420c"
      },
      "source": [
        "LCV.alphas_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.e+02, 1.e+02, 1.e+01, 1.e+00, 1.e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFGFyKF0PUdX",
        "outputId": "8f0d432e-05cc-4d94-eb13-f626281165c8"
      },
      "source": [
        "LCV.mse_path_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2457470.27034474, 2339293.19145847, 2436683.57769526,\n",
              "        2431356.87282384, 2318598.28824797],\n",
              "       [2237795.27985046, 2126456.28194575, 2221697.69265532,\n",
              "        2219823.4132731 , 2115351.51653151],\n",
              "       [1459634.12225611, 1436545.75405552, 1492598.54466899,\n",
              "        1498114.58651732, 1394267.18997702],\n",
              "       [1259014.03201153, 1217167.26107947, 1243701.38442841,\n",
              "        1267018.57150108, 1199495.40269138],\n",
              "       [1257699.59097933, 1211392.85606809, 1235343.08323397,\n",
              "        1261978.65250728, 1241540.00907851]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyRL0xtbPy0Q",
        "outputId": "dd8455c2-95bc-4cdf-9d5d-26c62704b535"
      },
      "source": [
        "np.mean(LCV.mse_path_, axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1734322.65908843, 1666171.06892146, 1726004.85653639,\n",
              "       1735658.41932453, 1653850.48130528])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99qOg2D5SuNW",
        "outputId": "939128e5-6a00-42d2-c7ea-605c2c64ad65"
      },
      "source": [
        "x_train.drop(\"Unnamed: 0\",axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmwP5T1fS4QN",
        "outputId": "d6398556-5a02-462a-a8b9-7895d2e457e2"
      },
      "source": [
        "x_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['carat', 'depth', 'table', 'x', 'y', 'z', 'cut_Good', 'cut_Ideal',\n",
              "       'cut_Premium', 'cut_Very Good', 'color_E', 'color_F', 'color_G',\n",
              "       'color_H', 'color_I', 'color_J', 'clarity_IF', 'clarity_SI1',\n",
              "       'clarity_SI2', 'clarity_VS1', 'clarity_VS2', 'clarity_VVS1',\n",
              "       'clarity_VVS2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7HzFipKicdq"
      },
      "source": [
        "**Задача 3.12 (0.5 балла)** Обучите итоговую Lasso-регрессию с выбранным параметром $\\alpha$ на тренировочной выборке. Выведите полученные коэффициенты и прокомментируйте, какие признаки оказались неинформативными, а какие – наиболее информативными. Приведите возможное смысловое объяснение этого результата."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsPFpHOMicdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9a64cd-4192-47c3-8756-8ed7bd854b01"
      },
      "source": [
        "LS = Lasso(alpha = 1)\n",
        "LS.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False,\n",
              "      positive=False, precompute=False, random_state=None, selection='cyclic',\n",
              "      tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rO_q7XaQSGj",
        "outputId": "6735f432-b287-46e8-d69b-6dc2f0894eaa"
      },
      "source": [
        "LS.coef_\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5413.02755763,  -103.04543918,   -70.1522232 , -1188.39157368,\n",
              "          -0.        ,   -55.011359  ,   515.70908217,   765.21353606,\n",
              "         696.52471523,   672.66358862,  -156.78664362,  -217.38581005,\n",
              "        -425.68219474,  -911.33527221, -1397.14859637, -2288.56472859,\n",
              "        4640.62735893,  3011.95760466,  2036.40757244,  3899.62233854,\n",
              "        3609.03077334,  4311.69036606,  4274.83919753])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "qdn6TStqQbp6",
        "outputId": "df28bab0-6f0c-4b4f-f738-8bfe9676fdda"
      },
      "source": [
        "x_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut_Good</th>\n",
              "      <th>cut_Ideal</th>\n",
              "      <th>cut_Premium</th>\n",
              "      <th>cut_Very Good</th>\n",
              "      <th>color_E</th>\n",
              "      <th>color_F</th>\n",
              "      <th>color_G</th>\n",
              "      <th>color_H</th>\n",
              "      <th>color_I</th>\n",
              "      <th>color_J</th>\n",
              "      <th>clarity_IF</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48902</th>\n",
              "      <td>-0.607459</td>\n",
              "      <td>0.174922</td>\n",
              "      <td>-1.099672</td>\n",
              "      <td>-0.553739</td>\n",
              "      <td>-0.520544</td>\n",
              "      <td>-0.522514</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46602</th>\n",
              "      <td>-0.544169</td>\n",
              "      <td>-0.941922</td>\n",
              "      <td>1.137995</td>\n",
              "      <td>-0.437849</td>\n",
              "      <td>-0.450499</td>\n",
              "      <td>-0.536684</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53040</th>\n",
              "      <td>-0.185524</td>\n",
              "      <td>0.523936</td>\n",
              "      <td>-0.204605</td>\n",
              "      <td>-0.054519</td>\n",
              "      <td>-0.038985</td>\n",
              "      <td>0.015965</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35494</th>\n",
              "      <td>-0.818426</td>\n",
              "      <td>1.361569</td>\n",
              "      <td>0.242928</td>\n",
              "      <td>-0.883581</td>\n",
              "      <td>-0.897036</td>\n",
              "      <td>-0.749241</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41390</th>\n",
              "      <td>-0.797330</td>\n",
              "      <td>-0.034486</td>\n",
              "      <td>0.690462</td>\n",
              "      <td>-0.812264</td>\n",
              "      <td>-0.835746</td>\n",
              "      <td>-0.820094</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          carat     depth     table  ...  clarity_VS2  clarity_VVS1  clarity_VVS2\n",
              "48902 -0.607459  0.174922 -1.099672  ...            0             0             1\n",
              "46602 -0.544169 -0.941922  1.137995  ...            0             0             0\n",
              "53040 -0.185524  0.523936 -0.204605  ...            0             0             0\n",
              "35494 -0.818426  1.361569  0.242928  ...            0             0             0\n",
              "41390 -0.797330 -0.034486  0.690462  ...            0             0             1\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFd1s9hRicdr"
      },
      "source": [
        "**Задача 3.13 (0.4 балла)** Сделайте предсказания обученной Lasso-регрессии на тестовой выборке и сравните среднеквадратичную ошибку с ошибкой обычной линейной регрессии из задачи 3.7. Какую модель лучше использовать для предсказаний? Приведите возможное объяснение, почему одна модель оказалась лучше другой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Nus_mEicdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ca5c2f-c4cb-4b99-bfd9-72aff2674509"
      },
      "source": [
        "LR = LinearRegression()\n",
        "LR.fit(x_train,y_train)\n",
        "y_predicted = LR.predict(x_train)\n",
        "mean_squared_error(y_test,LR.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1378046.960236092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ5hTAvITppn",
        "outputId": "f6af42de-a051-4cd4-c88b-9834e43180d0"
      },
      "source": [
        "LS = Lasso(alpha=0.1)\n",
        "LS.fit(x_train,y_train)\n",
        "mean_squared_error(y_test,LS.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1378548.296558068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7pMIGwyVR_y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}